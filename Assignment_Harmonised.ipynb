{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ce71e5",
   "metadata": {},
   "source": [
    "# Group Assignment QF627\n",
    "\n",
    "<font size = 5>**Group Members:**</font>\n",
    "* Anna Germaine Lim\n",
    "* Chen Pengyu\n",
    "* Gregory Tan\n",
    "* Zenith Tay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8c752",
   "metadata": {},
   "source": [
    "# Contribution Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad19db",
   "metadata": {},
   "source": [
    "Name        |Work Contributed                                                                           |\n",
    "---         |   ---                                                                                     |\n",
    "Zenith      |Supervised Learning Models and Codes, Report Writing, Team Reflections                           |\n",
    "Gregory     |   Momentum Trading Strategies and Codes, Report Writing and Collation, Team Reflections             |\n",
    "Anna        |Mean-Reversion Strategies and Codes, Report Writing, Team Reflections                                |\n",
    "Pengyu      |Report Writing, Team Reflections, Attempts on unsupervised learning                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705721f7",
   "metadata": {},
   "source": [
    "# Prep Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b987bf1f",
   "metadata": {},
   "source": [
    "## Packages Used in This Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7104e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Download\n",
    "\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "## For Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For Supervised learning\n",
    "\n",
    "# Model specification\n",
    "\n",
    "# linear models\n",
    "from sklearn.linear_model import LinearRegression # Linear Regression\n",
    "from sklearn.linear_model import ElasticNet # Elastic Net\n",
    "from sklearn.linear_model import Lasso # LASSO\n",
    "\n",
    "# oldies\n",
    "from sklearn.svm import SVR # Support Vector Machine\n",
    "from sklearn.neighbors import KNeighborsRegressor # K-Nearest Neighbor\n",
    "\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor# Decision Tree\n",
    "\n",
    "# bagging\n",
    "from sklearn.ensemble import RandomForestRegressor # Random Forest\n",
    "from sklearn.ensemble import ExtraTreesRegressor # Extra Trees\n",
    "\n",
    "# boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor # Gradient Boosting Tree\n",
    "from sklearn.ensemble import AdaBoostRegressor # Adaptive Boosting\n",
    "\n",
    "# time-series\n",
    "import statsmodels.tsa.arima.model as stats # ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature engineering\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338924db",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3499704",
   "metadata": {},
   "source": [
    "### Download of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2421058",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2006-11-01\"\n",
    "end_date = \"2025-11-13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e838feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data (ticker: list[str] | str,\n",
    "                   start_date = start_date, \n",
    "                   end_date = end_date,\n",
    "                   close_only = False) -> pd.DataFrame:\n",
    "    if close_only == False:\n",
    "        data =\\\n",
    "        (\n",
    "            yf.download(tickers = ticker,\n",
    "                        start = start_date,\n",
    "                        end = end_date)\n",
    "        )\n",
    "    else:\n",
    "        data =\\\n",
    "        (\n",
    "            yf.download(tickers = ticker,\n",
    "                        start = start_date,\n",
    "                        end = end_date)\n",
    "                        [\"Close\"]\n",
    "        )    \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preallocate empty array and assign slice by chrisaycock\n",
    "\n",
    "def np_shift(arr, num, fill_value=np.nan):\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:num] = fill_value\n",
    "        result[num:] = arr[:-num]\n",
    "    elif num < 0:\n",
    "        result[num:] = fill_value\n",
    "        result[:num] = arr[-num:]\n",
    "    else:\n",
    "        result[:] = arr\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be39a61",
   "metadata": {},
   "source": [
    "### Mean Reversion Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31724f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bollinger_band(price_data: pd.Series,\n",
    "                            window: int = 14,\n",
    "                                                ) -> pd.Series:\n",
    "\n",
    "    price = price_data[price_col]\n",
    "\n",
    "    std_dev_series =\\\n",
    "    (\n",
    "        price\n",
    "        .rolling(window = window)\n",
    "        .std()\n",
    "    )\n",
    "\n",
    "    price_high =\\\n",
    "    (\n",
    "        price + 2*std_dev_series\n",
    "    )\n",
    "\n",
    "    price_low =\\\n",
    "    (\n",
    "        price - 2*std_dev_series\n",
    "    )\n",
    "\n",
    "    return price_high, price_low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61fd69",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moving Average\n",
    "\n",
    "def generate_moving_avg(price_data: pd.Series,\n",
    "                        window: int\n",
    "                                              ) -> pd.Series:\n",
    "    \n",
    "    ma_series =\\\n",
    "    (\n",
    "        pd.Series\n",
    "        (   \n",
    "            price_data\n",
    "            .rolling(window = window)\n",
    "            .mean(),\n",
    "\n",
    "            name = 'MA' + str(window)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return ma_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b816573",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exponential Moving Average\n",
    "\n",
    "def generate_EMA(price_data: pd.Series, \n",
    "                    window: int\n",
    "                            ) -> pd.Series:\n",
    "    EMA = pd.Series(price_data\n",
    "                    .ewm(span = window,\n",
    "                         min_periods = window)\n",
    "                    .mean(),\n",
    "                    name = \"EMA_\" + str(window)\n",
    "                    )\n",
    "    return EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Moving Avg Cross Signal\n",
    "\n",
    "def generate_moving_avg_cross_signal(long_ma: pd.Series,\n",
    "                                    short_ma: pd.Series) -> pd.Series:\n",
    "    \n",
    "    ## Sanity Check\n",
    "    if len(long_ma) != len(short_ma):\n",
    "        print('MA series lengths not equal, please check')\n",
    "        return\n",
    "\n",
    "    ## Return Signals\n",
    "    else:\n",
    "\n",
    "        moving_avg_cross_positions = np.where(short_ma > long_ma, 1.0, 0.0)\n",
    "        moving_avg_cross_positions = np.where(short_ma < long_ma, -1.0 , moving_avg_cross_positions)\n",
    "\n",
    "        moving_avg_cross_signals = np.where(moving_avg_cross_positions - np_shift(moving_avg_cross_positions,1) > 0, 1, 0)\n",
    "        moving_avg_cross_signals = np.where(moving_avg_cross_positions - np_shift(moving_avg_cross_positions, 1) < 0, -1, moving_avg_cross_signals)\n",
    "\n",
    "        buy_or_sell = pd.DataFrame({'MA_Cross_Signal':moving_avg_cross_signals, 'MA_Cross_Position': moving_avg_cross_positions},\n",
    "                                   index = long_ma.index\n",
    "                                   )\n",
    "\n",
    "        return buy_or_sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC\n",
    "\n",
    "def generate_rate_of_change(price_data: pd.Series,\n",
    "                            n: int\n",
    "                            ) -> pd.Series:\n",
    "    \n",
    "    ROC = pd.Series(\n",
    "                        (price_data - price_data.diff(n)) / price_data.diff(n),\n",
    "                        name = 'ROC'+str(n),\n",
    "                        # index = price_data.index\n",
    "                    )\n",
    "    \n",
    "    return ROC\n",
    "\n",
    "def generate_rate_of_change_signal(roc_data: pd.Series) -> pd.Series:\n",
    "\n",
    "    roc_position = pd.Series(np.where(roc_data > 0, 1.0, 0.0), index=roc_data.index, name = 'ROC_Position')\n",
    "    roc_signal = roc_position.diff()\n",
    "    roc_signal.name = 'ROC_Signal'\n",
    "    \n",
    "    # roc_signal = roc_position - np_shift(roc_position, 1)\n",
    "\n",
    "\n",
    "    # buy_or_sell = pd.DataFrame({'ROC_Position': roc_position, 'ROC_Signal': roc_signal},\n",
    "    #                         #    index = roc_data.index\n",
    "    #                            )\n",
    "\n",
    "    return pd.concat([roc_position, roc_signal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0299b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RSI\n",
    "\n",
    "def generate_RSI(series, period):\n",
    "    \n",
    "    delta = series.diff().dropna()\n",
    "    \n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    \n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    \n",
    "    u[u.index[period - 1]] = np.mean( u[:period] ) # \n",
    "    \n",
    "    u = u.drop(u.index[:(period - 1)\n",
    "                      ]\n",
    "              )\n",
    "    \n",
    "    d[d.index[period - 1]] = np.mean( d[:period] )\n",
    "    \n",
    "    d = d.drop(d.index[:(period - 1)\n",
    "                      ]\n",
    "              )\n",
    "    \n",
    "    rs = u.ewm(com = period - 1, adjust = False).mean() / \\\n",
    "         d.ewm(com = period - 1, adjust = False).mean()\n",
    "    \n",
    "    return 100 - 100 / (1 + rs)\n",
    "\n",
    "def generate_rsi_signal(rsi_data: pd.Series) -> pd.Series:\n",
    "\n",
    "    rsi_position = pd.Series(np.where(rsi_data > 50, 1.0, -1.0), \n",
    "                             index= rsi_data.index, \n",
    "                             name = 'rsi_position')\n",
    "    \n",
    "    rsi_signal = rsi_position.diff()\n",
    "    rsi_signal.name = 'rsi_signal'\n",
    "    \n",
    "    # rsi_signal = rsi_position - np_shift(rsi_position, 1)\n",
    "\n",
    "\n",
    "    # buy_or_sell = pd.DataFrame({'rsi_position': rsi_position, 'rsi_signal': rsi_signal},\n",
    "    #                         #    index = rsi_data.index\n",
    "    #                            )\n",
    "\n",
    "    return pd.concat([rsi_position, rsi_signal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_force_index(data_price: pd.Series, data_vol: pd.Series, period: int) -> pd.Series:\n",
    "\n",
    "    indicator = data_price.diff() * data_vol\n",
    "    lag_indicator = indicator.ewm(span = period, adjust = False).mean()\n",
    "\n",
    "    return lag_indicator\n",
    "\n",
    "def generate_force_index_signal(data: pd.Series) -> pd.Series:\n",
    "\n",
    "    position = pd.Series(np.where(data >= 0, 1.0, -1.0),\n",
    "                        index = data.index,\n",
    "                        name = 'FI_position'\n",
    "                        )\n",
    "    signal = position.diff()/2\n",
    "    signal.name = 'FI_signal'\n",
    "\n",
    "    return pd.concat([position, signal], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2f941",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Annualised Sharpe\n",
    "\n",
    "def annual_sharpe(returns):\n",
    "    days = (returns.index[-1] - returns.index[0]).days\n",
    "    \n",
    "    return\\\n",
    "    (\n",
    "        (\n",
    "            (1+returns).prod()\n",
    "            **(365/days) \n",
    "            - 1\n",
    "        )\n",
    "        /\n",
    "        returns.std()\n",
    "        /\n",
    "        np.sqrt(252)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CAGR\n",
    "\n",
    "def cagr(returns: pd.Series) -> float:\n",
    "    days = (returns.index[-1] - returns.index[0]).days\n",
    "    return ( (1 + returns).prod() )**(365/days) - 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e52960",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Max Drawdown\n",
    "\n",
    "def max_drawdown(cumulative_returns):\n",
    "    max_performance = cumulative_returns.cummax()\n",
    "    dd = ((max_performance - cumulative_returns) / max_performance).max()\n",
    "    return dd\n",
    "\n",
    "\n",
    "### Longest Drawdown\n",
    "\n",
    "def calculate_longest_drawdown(cumulative_returns):\n",
    "    drawdown = cumulative_returns.cummax() - cumulative_returns\n",
    "    period =\\\n",
    "    (\n",
    "        np\n",
    "        .diff(np\n",
    "              .append(drawdown[drawdown == 0].index, \n",
    "                      drawdown.index[-1: ]\n",
    "                    )\n",
    "            )\n",
    "    )\n",
    "    return period.max() / np.timedelta64(1, \"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_returns(returns_series: pd.Series, to_print: bool = False):\n",
    "    \n",
    "    cum_returns_series = (1 + returns_series).cumprod()\n",
    "\n",
    "    tot_returns = (1 + returns_series).prod() - 1\n",
    "    CAGR = cagr(returns_series)\n",
    "    Annualised_Sharpe = annual_sharpe(returns_series)\n",
    "    Max_DD = max_drawdown(cum_returns_series)\n",
    "    Longest_DD = calculate_longest_drawdown(cum_returns_series)\n",
    "\n",
    "    if to_print == True:\n",
    "      print('-- Summary of Returns -- \\n',\n",
    "            f'Total Returns: {tot_returns: .2%} \\n',\n",
    "            f'CAGR: {CAGR: .2%} \\n',\n",
    "            f'Annualised_Sharpe: {Annualised_Sharpe: .2%} \\n',\n",
    "            f'Max Drawdown: {Max_DD: .2%} \\n',\n",
    "            f'Longest Drawdown (Days): {Longest_DD}'            \n",
    "            )\n",
    "\n",
    "    return pd.Series([tot_returns, CAGR, Annualised_Sharpe, Max_DD, Longest_DD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f181706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_returns(price_data: pd.DataFrame,\n",
    "                     price_col: 'str' = 'Close') -> pd.Series:\n",
    "    \n",
    "    returns_series = price_data[price_col].pct_change()\n",
    "    cum_returns_series = (1 + returns_series).cumprod()\n",
    "\n",
    "    tot_returns = float(cum_returns_series.iloc[-1].iloc[0])\n",
    "\n",
    "    print('=== Summary of Returns === \\n',\n",
    "          f'Total Returns = {tot_returns: .2%}'\n",
    "          )\n",
    "\n",
    "    return tot_returns, returns_series, cum_returns_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabca932",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aaffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_data =\\\n",
    "(\n",
    "    download_data(\"SPY\", start_date, end_date)\n",
    ")\n",
    "spy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf17eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_data = \\\n",
    "    (\n",
    "        spy_data\n",
    "        .droplevel(\n",
    "            level = 1,\n",
    "            axis =1\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d8816",
   "metadata": {},
   "source": [
    "# Part 1 and 2: Analysis, Visualisation and Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc0fa08",
   "metadata": {},
   "source": [
    "Data Wrangling and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4aad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pct = 0.75\n",
    "train_test_split_index = int(train_pct*len(spy_data))\n",
    "spy_train_data =\\\n",
    "    (\n",
    "        spy_data\n",
    "        .copy()\n",
    "        .iloc[ : train_test_split_index]\n",
    "    )\n",
    "\n",
    "spy_test_data =\\\n",
    "    (\n",
    "        spy_data\n",
    "        .copy()\n",
    "        .iloc[train_test_split_index : ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spy_train_data) + len(spy_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cce909",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spy_train_data, spy_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39abe297",
   "metadata": {},
   "source": [
    "## (1A) Momentum Trading Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057cabc",
   "metadata": {},
   "source": [
    "### Functions to Generate Positions and Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d16df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moving Average\n",
    "\n",
    "def generate_moving_avg(price_data: pd.Series,\n",
    "                        window: int\n",
    "                                              ) -> pd.Series:\n",
    "    \n",
    "    ma_series =\\\n",
    "    (\n",
    "        pd.Series\n",
    "        (   \n",
    "            price_data\n",
    "            .rolling(window = window)\n",
    "            .mean(),\n",
    "\n",
    "            name = 'MA' + str(window)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return ma_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6578ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exponential Moving Average\n",
    "\n",
    "def generate_EMA(price_data: pd.Series, \n",
    "                    window: int\n",
    "                            ) -> pd.Series:\n",
    "    EMA = pd.Series(price_data\n",
    "                    .ewm(span = window,\n",
    "                         min_periods = window)\n",
    "                    .mean(),\n",
    "                    name = \"EMA_\" + str(window)\n",
    "                    )\n",
    "    return EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a58c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_moving_avg_cross_signal(long_ma: pd.Series,\n",
    "                                    short_ma: pd.Series) -> pd.Series:\n",
    "    \n",
    "    ## Sanity Check\n",
    "    if len(long_ma) != len(short_ma):\n",
    "        print('MA series lengths not equal, please check')\n",
    "        return\n",
    "\n",
    "    ## Return Signals\n",
    "    else:\n",
    "\n",
    "        moving_avg_cross_positions = np.where(short_ma > long_ma, 1.0, 0.0)\n",
    "        moving_avg_cross_positions = np.where(short_ma < long_ma, -1.0 , moving_avg_cross_positions)\n",
    "\n",
    "        moving_avg_cross_signals = np.where(moving_avg_cross_positions - np_shift(moving_avg_cross_positions,1) > 0, 1, 0)\n",
    "        moving_avg_cross_signals = np.where(moving_avg_cross_positions - np_shift(moving_avg_cross_positions, 1) < 0, -1, moving_avg_cross_signals)\n",
    "\n",
    "        buy_or_sell = pd.DataFrame({'MA_Cross_Signal':moving_avg_cross_signals, 'MA_Cross_Position': moving_avg_cross_positions},\n",
    "                                   index = long_ma.index\n",
    "                                   )\n",
    "\n",
    "        return buy_or_sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c826d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rate of Change\n",
    "\n",
    "def generate_rate_of_change(price_data: pd.Series,\n",
    "                            n: int\n",
    "                            ) -> pd.Series:\n",
    "    \n",
    "    ROC = pd.Series(\n",
    "                        (price_data - price_data.diff(n)) / price_data.diff(n),\n",
    "                        name = 'ROC'+str(n),\n",
    "                        # index = price_data.index\n",
    "                    )\n",
    "    \n",
    "    return ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05813dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rate_of_change_signal(roc_data: pd.Series) -> pd.Series:\n",
    "\n",
    "    roc_position = pd.Series(np.where(roc_data > 0, 1.0, 0.0), index=roc_data.index, name = 'ROC_Position')\n",
    "    roc_signal = roc_position.diff()\n",
    "    roc_signal.name = 'ROC_Signal'\n",
    "    \n",
    "    # roc_signal = roc_position - np_shift(roc_position, 1)\n",
    "\n",
    "\n",
    "    # buy_or_sell = pd.DataFrame({'ROC_Position': roc_position, 'ROC_Signal': roc_signal},\n",
    "    #                         #    index = roc_data.index\n",
    "    #                            )\n",
    "\n",
    "    return pd.concat([roc_position, roc_signal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc0bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RSI\n",
    "\n",
    "def generate_RSI(series, period):\n",
    "    \n",
    "    delta = series.diff().dropna()\n",
    "    \n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    \n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    \n",
    "    u[u.index[period - 1]] = np.mean( u[:period] ) # \n",
    "    \n",
    "    u = u.drop(u.index[:(period - 1)\n",
    "                      ]\n",
    "              )\n",
    "    \n",
    "    d[d.index[period - 1]] = np.mean( d[:period] )\n",
    "    \n",
    "    d = d.drop(d.index[:(period - 1)\n",
    "                      ]\n",
    "              )\n",
    "    \n",
    "    rs = u.ewm(com = period - 1, adjust = False).mean() / \\\n",
    "         d.ewm(com = period - 1, adjust = False).mean()\n",
    "    \n",
    "    return 100 - 100 / (1 + rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e21f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rsi_signal(rsi_data: pd.Series) -> pd.Series:\n",
    "\n",
    "    rsi_position = pd.Series(np.where(rsi_data > 50, 1.0, -1.0), \n",
    "                             index= rsi_data.index, \n",
    "                             name = 'rsi_position')\n",
    "    \n",
    "    rsi_signal = rsi_position.diff()\n",
    "    rsi_signal.name = 'rsi_signal'\n",
    "    \n",
    "    # rsi_signal = rsi_position - np_shift(rsi_position, 1)\n",
    "\n",
    "\n",
    "    # buy_or_sell = pd.DataFrame({'rsi_position': rsi_position, 'rsi_signal': rsi_signal},\n",
    "    #                         #    index = rsi_data.index\n",
    "    #                            )\n",
    "\n",
    "    return pd.concat([rsi_position, rsi_signal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9def07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_force_index(data_price: pd.Series, data_vol: pd.Series, period: int) -> pd.Series:\n",
    "\n",
    "    indicator = data_price.diff() * data_vol\n",
    "    lag_indicator = indicator.ewm(span = period, adjust = False).mean()\n",
    "\n",
    "    return lag_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d07118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_force_index_signal(data: pd.Series) -> pd.Series:\n",
    "\n",
    "    position = pd.Series(np.where(data >= 0, 1.0, -1.0),\n",
    "                        index = data.index,\n",
    "                        name = 'FI_position'\n",
    "                        )\n",
    "    signal = position.diff()/2\n",
    "    signal.name = 'FI_signal'\n",
    "\n",
    "    return pd.concat([position, signal], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0a18f",
   "metadata": {},
   "source": [
    "### Functions to Generate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7257f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Annualised Sharpe\n",
    "\n",
    "def annual_sharpe(returns):\n",
    "    days = (returns.index[-1] - returns.index[0]).days\n",
    "    \n",
    "    return\\\n",
    "    (\n",
    "        (\n",
    "            (1+returns).prod()\n",
    "            **(365/days) \n",
    "            - 1\n",
    "        )\n",
    "        /\n",
    "        returns.std()\n",
    "        /\n",
    "        np.sqrt(252)\n",
    "    )\n",
    "\n",
    "## CAGR\n",
    "\n",
    "def cagr(returns: pd.Series) -> float:\n",
    "    days = (returns.index[-1] - returns.index[0]).days\n",
    "    return ( (1 + returns).prod() )**(365/days) - 1   \n",
    "\n",
    "### Max Drawdown\n",
    "\n",
    "def max_drawdown(cumulative_returns):\n",
    "    max_performance = cumulative_returns.cummax()\n",
    "    dd = ((max_performance - cumulative_returns) / max_performance).max()\n",
    "    return dd\n",
    "\n",
    "### Longest Drawdown\n",
    "\n",
    "def calculate_longest_drawdown(cumulative_returns):\n",
    "    drawdown = cumulative_returns.cummax() - cumulative_returns\n",
    "    period =\\\n",
    "    (\n",
    "        np\n",
    "        .diff(np\n",
    "              .append(drawdown[drawdown == 0].index, \n",
    "                      drawdown.index[-1: ]\n",
    "                    )\n",
    "            )\n",
    "    )\n",
    "    return period.max() / np.timedelta64(1, \"D\")\n",
    "\n",
    "### Evaluate Returns in Totality\n",
    "\n",
    "def evaluate_returns(returns_series: pd.Series, to_print: bool = False):\n",
    "    \n",
    "    cum_returns_series = (1 + returns_series).cumprod()\n",
    "\n",
    "    tot_returns = (1 + returns_series).prod() - 1\n",
    "    CAGR = cagr(returns_series)\n",
    "    Annualised_Sharpe = annual_sharpe(returns_series)\n",
    "    Max_DD = max_drawdown(cum_returns_series)\n",
    "    Longest_DD = calculate_longest_drawdown(cum_returns_series)\n",
    "\n",
    "    if to_print == True:\n",
    "      print('-- Summary of Returns -- \\n',\n",
    "            f'Total Returns: {tot_returns: .2%} \\n',\n",
    "            f'CAGR: {CAGR: .2%} \\n',\n",
    "            f'Annualised_Sharpe: {Annualised_Sharpe: .2%} \\n',\n",
    "            f'Max Drawdown: {Max_DD: .2%} \\n',\n",
    "            f'Longest Drawdown (Days): {Longest_DD}'            \n",
    "            )\n",
    "\n",
    "    return pd.Series([tot_returns, CAGR, Annualised_Sharpe, Max_DD, Longest_DD])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ae5c6",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proportion = 0.75\n",
    "\n",
    "spy_data =\\\n",
    "(\n",
    "    download_data('SPY',\n",
    "                  start_date = '2006-11-01',\n",
    "                  end_date = '2025-11-12')\n",
    "    .droplevel(level = 1,\n",
    "               axis = 1)\n",
    "    [['Close', 'Volume']]\n",
    ").resample('W-FRI').agg({'Close': 'last', 'Volume': 'sum'})\n",
    "\n",
    "spy_train_data = spy_data[:int(train_proportion*len(spy_data))]\n",
    "\n",
    "spy_data_close = spy_train_data['Close'].to_frame()\n",
    "spy_data_returns = spy_train_data['Close'].pct_change().to_frame().rename(columns= {'Close': 'Returns'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab929e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_returns(spy_data_returns['Returns'], to_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b7b41",
   "metadata": {},
   "source": [
    "### FI Train (No Luck)\n",
    "FI Signals attempted to include volume to indicate strength of the turn. However for indication of trends, not very useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb71ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_periods = np.arange(10, 201, 10).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d8119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fi_Metrics(time_periods):\n",
    "\n",
    "    Metrics = pd.DataFrame()\n",
    "\n",
    "    for i in time_periods:\n",
    "\n",
    "        data = spy_data_returns.copy()\n",
    "        \n",
    "        data[f'fi{i}'] = generate_force_index(spy_data['Close'], spy_data['Volume'], i)\n",
    "        \n",
    "        data = pd.concat([data, generate_force_index_signal(data[f'fi{i}'])], axis = 1)\n",
    "        \n",
    "        data['Strat_returns'] = data['Returns'] * data['FI_position'].shift(1)\n",
    "        \n",
    "        # print(f'===Data for ROC{i}===')\n",
    "        strat_series = evaluate_returns(data['Strat_returns'])\n",
    "        strat_series.name = f'FI{i}'\n",
    "        \n",
    "        Metrics = pd.concat([Metrics, strat_series], axis = 1)\n",
    "\n",
    "    Metrics.index = ['Total Returns', 'CAGR', 'Annualised Sharpe', 'Max Drawdown', 'Longest Drawdown (Days)']\n",
    "    return Metrics.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1464fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_fi_Metrics(list(range(10,251,10))).sort_values(by = 'Annualised Sharpe', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4b6fdc",
   "metadata": {},
   "source": [
    "### ROC (No Luck)\n",
    "ROC Signals Significantly Underperformed the Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ROC_Metrics(time_periods):\n",
    "\n",
    "    ROC_Metrics = pd.DataFrame()\n",
    "\n",
    "    for i in time_periods:\n",
    "        roc_data = spy_data_returns.copy()\n",
    "        \n",
    "        roc_data[f'ROC{i}'] = generate_rate_of_change(spy_data_close['Close'], i)\n",
    "        roc_data = pd.concat([roc_data, generate_rate_of_change_signal(roc_data[f'ROC{i}'])], axis = 1)\n",
    "        roc_data['Strat_returns'] = roc_data['Returns'] * roc_data['ROC_Position'].shift(1)\n",
    "        \n",
    "        # print(f'===Data for ROC{i}===')\n",
    "        roc_series = evaluate_returns(roc_data['Strat_returns'])\n",
    "        roc_series.name = f'ROC{i}'\n",
    "        \n",
    "        ROC_Metrics = pd.concat([ROC_Metrics, roc_series], axis = 1)\n",
    "\n",
    "    ROC_Metrics.index = ['Total Returns', 'CAGR', 'Annualised Sharpe', 'Max Drawdown', 'Longest Drawdown (Days)']\n",
    "    return ROC_Metrics.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea69e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ROC_Metrics(time_periods).sort_values(by = 'Annualised Sharpe', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77a839",
   "metadata": {},
   "source": [
    "### RSI (No Luck Either)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda2001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_RSI_Metrics(time_periods):\n",
    "\n",
    "    Metrics = pd.DataFrame()\n",
    "\n",
    "    for i in time_periods:\n",
    "        data = spy_data_returns.copy()\n",
    "        \n",
    "        data[f'RSI{i}'] = generate_RSI(spy_data_close['Close'], i)\n",
    "        \n",
    "        data = pd.concat([data, generate_rsi_signal(data[f'RSI{i}'])], axis = 1)\n",
    "        \n",
    "        data['Strat_returns'] = data['Returns'] * data['rsi_position'].shift(1)\n",
    "        \n",
    "        # print(f'===Data for ROC{i}===')\n",
    "        strat_series = evaluate_returns(data['Strat_returns'])\n",
    "        strat_series.name = f'RSI{i}'\n",
    "        \n",
    "        Metrics = pd.concat([Metrics, strat_series], axis = 1)\n",
    "\n",
    "    Metrics.index = ['Total Returns', 'CAGR', 'Annualised Sharpe', 'Max Drawdown', 'Longest Drawdown (Days)']\n",
    "    return Metrics.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_RSI_Metrics(range(10, 252, 10)).sort_values(by = 'Annualised Sharpe', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79e2217",
   "metadata": {},
   "source": [
    "### MA and EMA\n",
    "Moving Average Crossovers seem more promising from the 10 years of data data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_list =\\\n",
    "(\n",
    "    list(range(10, 201, 10))\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ema_cross_metrics(short_ma: list[int], long_ma: list[int]) -> pd.Series:\n",
    "    \n",
    "    ma_cross_data = spy_data_close.copy()\n",
    "    ma_cross_summary_table = pd.DataFrame()\n",
    "\n",
    "    for j in long_ma:\n",
    "\n",
    "        for i in short_ma:\n",
    "\n",
    "            if i < j:\n",
    "            \n",
    "                short_ma_cross_data = generate_EMA(ma_cross_data['Close'], i)             \n",
    "                long_ma_cross_data = generate_EMA(ma_cross_data['Close'], j)\n",
    "\n",
    "                ma_cross_returns =\\\n",
    "                (\n",
    "                    pd\n",
    "                    .concat(\n",
    "                            (spy_data_returns, generate_moving_avg_cross_signal(long_ma_cross_data, short_ma_cross_data)),\n",
    "                            axis = 1\n",
    "                            )\n",
    "                )\n",
    "\n",
    "                ma_cross_returns['Strat_Returns'] = ma_cross_returns['Returns']*ma_cross_returns['MA_Cross_Position'].shift(1)\n",
    "\n",
    "                ma_cross_summary_stat_series = evaluate_returns(ma_cross_returns['Strat_Returns'])\n",
    "                ma_cross_summary_stat_series.name = f'EMA{i} + EMA{j}'\n",
    "\n",
    "\n",
    "                ma_cross_summary_table = pd.concat([ma_cross_summary_table, ma_cross_summary_stat_series], axis = 1)\n",
    "\n",
    "    ma_cross_summary_table.index = ['Total Returns', 'CAGR', 'Annualised Sharpe', 'Max Drawdown', 'Longest Drawdown (Days)']\n",
    "    return ma_cross_summary_table.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c695029",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ema_cross_metrics(MA_list, MA_list).sort_values(by = 'Annualised Sharpe', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a593b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ma_cross_metrics(short_ma: list[int], long_ma: list[int]) -> pd.Series:\n",
    "    \n",
    "    ma_cross_data = spy_data_close.copy()\n",
    "\n",
    "    ma_cross_summary_table = pd.DataFrame()\n",
    "\n",
    "    for j in long_ma:\n",
    "\n",
    "        for i in short_ma:\n",
    "\n",
    "            if i < j:\n",
    "            \n",
    "                short_ma_cross_data = generate_moving_avg(ma_cross_data['Close'], i)\n",
    "                long_ma_cross_data = generate_moving_avg(ma_cross_data['Close'], j)\n",
    "\n",
    "                ma_cross_returns =\\\n",
    "                (\n",
    "                    pd\n",
    "                    .concat(\n",
    "                            (spy_data_returns, generate_moving_avg_cross_signal(long_ma_cross_data, short_ma_cross_data)),\n",
    "                            axis = 1\n",
    "                            )\n",
    "                )\n",
    "\n",
    "                ma_cross_returns['Strat_Returns'] = ma_cross_returns['Returns']*ma_cross_returns['MA_Cross_Position'].shift(1)\n",
    "\n",
    "                ma_cross_summary_stat_series = evaluate_returns(ma_cross_returns['Strat_Returns'])\n",
    "                ma_cross_summary_stat_series.name = f'MA{i} + MA{j}'\n",
    "\n",
    "\n",
    "                ma_cross_summary_table = pd.concat([ma_cross_summary_table, ma_cross_summary_stat_series], axis = 1)\n",
    "\n",
    "    ma_cross_summary_table.index = ['Total Returns', 'CAGR', 'Annualised Sharpe', 'Max Drawdown', 'Longest Drawdown (Days)']\n",
    "    return ma_cross_summary_table.T, ma_cross_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9394a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_cross_summary = generate_ma_cross_metrics(MA_list, MA_list)[0]\n",
    "ma_cross_summary.sort_values(by = 'Total Returns', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43dc9e",
   "metadata": {},
   "source": [
    "### Test Dataset\n",
    "Moving Average Was tested against benchmark, with allowance of test data to spillover into training data to allow the Moving Average to Generate Signals at the start of the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabfa6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 160\n",
    "\n",
    "spy_test_data = spy_data[int(train_proportion*len(spy_data)-row):]\n",
    "\n",
    "spy_data_close = spy_test_data['Close'].to_frame()\n",
    "spy_data_returns = spy_test_data['Close'].pct_change().to_frame().rename(columns= {'Close': 'Returns'})\n",
    "\n",
    "# display(spy_test_data[row:])\n",
    "\n",
    "evaluate_returns(spy_data_returns.loc[spy_data_returns.index[row:],'Returns'], to_print=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_returns(generate_ma_cross_metrics([40], [160])[1]['Strat_Returns'], to_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e33218",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('== Strategy Return of MA ==')\n",
    "evaluate_returns(generate_ma_cross_metrics([40], [160])[1]['Strat_Returns'], to_print=True);\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('== Benchmark Returns ==')\n",
    "evaluate_returns(spy_data_returns.loc[spy_data_returns.index[160:],'Returns'], to_print=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b634c",
   "metadata": {},
   "source": [
    "## (1B) Mean Reverting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ca005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_bollinger_strategy(\n",
    "        old_df: pd.DataFrame,\n",
    "        period: int,\n",
    "        std_dev: int\n",
    ") -> pd.DataFrame:\n",
    "    df = old_df.copy()\n",
    "\n",
    "    df[f'sma_{period}'] = \\\n",
    "    (\n",
    "        df['Close']\n",
    "        .rolling(period)\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    df['std_dev'] = \\\n",
    "    (\n",
    "        df['Close']\n",
    "        .rolling(period)\n",
    "        .std()\n",
    "    )\n",
    "\n",
    "    df[f'upper_band_{std_dev}sd'] = \\\n",
    "    (\n",
    "        df[f'sma_{period}'] +\n",
    "        (\n",
    "            df['std_dev'] * std_dev\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df[f'lower_band_{std_dev}sd'] = \\\n",
    "    (\n",
    "        df[f'sma_{period}'] -\n",
    "        (\n",
    "            df['std_dev'] * std_dev\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd136237",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    setup_bollinger_strategy(spy_train_data,\n",
    "                             20,\n",
    "                             2).iloc[:,-2:]\n",
    "                             .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667abbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train_data_bollinger = \\\n",
    "(\n",
    "    setup_bollinger_strategy(spy_train_data,\n",
    "                             20,\n",
    "                             2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals(\n",
    "        old_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    df = old_df.copy()\n",
    "    \n",
    "    signal = 0\n",
    "\n",
    "    lst_signal = []\n",
    "\n",
    "    for index, item in enumerate(df['Close']):\n",
    "        if index ==0:\n",
    "            lst_signal.append(0)\n",
    "            continue\n",
    "        prev_close = df['Close'].iloc[index-1] \n",
    "        close = df['Close'].iloc[index] \n",
    "        sma = df['sma_20'].iloc[index]\n",
    "        lower_band = df['lower_band_2sd'].iloc[index]\n",
    "        upper_band = df['upper_band_2sd'].iloc[index]\n",
    "\n",
    "        if signal == 0:\n",
    "            if (prev_close < lower_band) & (close > lower_band):\n",
    "                signal = 1\n",
    "            if (prev_close > upper_band) & (close < upper_band):\n",
    "                signal = -1\n",
    "        \n",
    "\n",
    "        if signal == -1:\n",
    "            if close < sma:\n",
    "                signal = 0\n",
    "        \n",
    "        if signal == 1:\n",
    "            if close > sma:\n",
    "                signal = 0\n",
    "        lst_signal.append(signal)\n",
    "\n",
    "    df['signal'] = lst_signal\n",
    "    df['position'] = \\\n",
    "    (\n",
    "        df['signal']\n",
    "        .ffill()\n",
    "        .shift(1)\n",
    "        .fillna(0)\n",
    "        .dropna()\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100df7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train_data_bollinger = \\\n",
    "(\n",
    "    generate_signals(spy_train_data_bollinger)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa334419",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train_data_bollinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_strategy_return(\n",
    "        old_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    df = old_df.copy()\n",
    "\n",
    "\n",
    "    df['daily_return'] = \\\n",
    "    (\n",
    "        (\n",
    "            df['Close']/\n",
    "            df['Close'].shift(1)\n",
    "        )\n",
    "        .apply(np.log)\n",
    "    )\n",
    "\n",
    "    df['cum_return'] = \\\n",
    "    (\n",
    "        df['daily_return']\n",
    "        .cumsum()\n",
    "        .apply(np.exp)\n",
    "    )\n",
    "\n",
    "    df['strategy_return'] = \\\n",
    "    (\n",
    "        (\n",
    "            df['position'] \n",
    "            *\n",
    "            df['daily_return']\n",
    "        )\n",
    "        .cumsum()\n",
    "        .apply(np.exp)\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train_data_bollinger = \\\n",
    "(\n",
    "    compute_strategy_return(spy_train_data_bollinger)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4086259",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train_data_bollinger[['strategy_return']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95cd3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train_data_bollinger[['Close','upper_band_2sd','lower_band_2sd']][:100].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46883b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_drawdown(old_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df = old_df.copy()\n",
    "\n",
    "    df['cum_max'] =\\\n",
    "    (\n",
    "        df['strategy_return']\n",
    "        .cummax()\n",
    "    )\n",
    "\n",
    "    df['drawdown'] = \\\n",
    "    (\n",
    "        df['cum_max'] -\n",
    "        df['strategy_return']\n",
    "    )\n",
    "    df['in_drawdown'] =\\\n",
    "    (\n",
    "        df['cum_max'] !=\n",
    "        df['strategy_return']\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train_data_bollinger = \\\n",
    "    (\n",
    "        compute_drawdown(spy_train_data_bollinger)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d5e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train_data_bollinger.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd190505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run back Testing on Test data\n",
    "spy_test_data_bollinger = \\\n",
    "(\n",
    "    setup_bollinger_strategy(spy_test_data,\n",
    "                            20,\n",
    "                            2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_test_data_bollinger =\\\n",
    "(\n",
    "    spy_test_data_bollinger\n",
    "    .pipe(generate_signals)\n",
    "    .pipe(compute_strategy_return)\n",
    "    .pipe(compute_drawdown)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_test_data_bollinger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e0f70d",
   "metadata": {},
   "source": [
    "### Result: Bollinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e800081",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_test_data_bollinger[['strategy_return','cum_max']].plot()\n",
    "spy_train_data_bollinger[['strategy_return','cum_max']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(spy_test_data_bollinger.iloc[-1,-4] \n",
    "-1\n",
    "*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Test Return (%): ',(spy_test_data_bollinger.iloc[-1,-4]-1) *100,'\\n'\n",
    "    'Train Return (%): ',(spy_train_data_bollinger.iloc[-1,-4] -1) *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter Tuning: Bollinger Squeeze; Band Expansion; Breakout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5649e853",
   "metadata": {},
   "source": [
    "#### Momentum Trading Strategy - RSI with MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI(old_df, period=14):\n",
    "    df = old_df.copy()\n",
    "    delta = df['Close'].diff().dropna()\n",
    "    \n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    \n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    \n",
    "    u[u.index[period - 1]] = np.mean( u[:period] ) # \n",
    "    \n",
    "    u = u.drop(u.index[:(period - 1)\n",
    "                      ]\n",
    "              )\n",
    "    \n",
    "    d[d.index[period - 1]] = np.mean( d[:period] )\n",
    "    \n",
    "    d = d.drop(d.index[:(period - 1)\n",
    "                      ]\n",
    "              )\n",
    "    \n",
    "    rs = u.ewm(com = period - 1, adjust = False).mean() / \\\n",
    "         d.ewm(com = period - 1, adjust = False).mean()\n",
    "    \n",
    "    df['rsi'] = 100 - 100 / (1 + rs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd451960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macd(old_df,\n",
    "        macd_long: int = 26,\n",
    "        macd_short: int = 12\n",
    "        ) -> pd.DataFrame:\n",
    "    \n",
    "    #MACD - for trend direction\n",
    "    \n",
    "    df = old_df.copy()\n",
    "    \n",
    "    df['macd_long'] = \\\n",
    "    (    \n",
    "        df['Close']\n",
    "        .ewm(span = macd_long,\n",
    "                adjust = False)\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    df['macd_short'] = \\\n",
    "    (\n",
    "        df['Close']\n",
    "        .ewm(span = macd_short,\n",
    "             adjust = False)\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    df['macd'] = \\\n",
    "    (\n",
    "        df['macd_short'] -\n",
    "        df['macd_long']\n",
    "    )\n",
    "\n",
    "    df['signal_line'] = \\\n",
    "    (\n",
    "        df['macd']\n",
    "        .ewm(span = 9,\n",
    "             adjust = False)\n",
    "        .mean()\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de13def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals_rsi_macd(\n",
    "        old_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    df = old_df.copy()\n",
    "    df['signal'] = \\\n",
    "    (\n",
    "        np\n",
    "        .select(\n",
    "            [\n",
    "                (df['rsi'] > 30) & (df['macd'] > df['signal_line']),\n",
    "                (df['rsi'] < 70) & (df['macd'] < df['signal_line'])\n",
    "            ],\n",
    "            [\n",
    "                1,\n",
    "                -1\n",
    "            ],\n",
    "            0\n",
    "        )\n",
    "    )\n",
    "    df['position'] = \\\n",
    "    (\n",
    "        df['signal']\n",
    "        .ffill()\n",
    "        .shift(1)\n",
    "        .fillna(0)\n",
    "        .dropna()\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train_data_rsi_macd =\\\n",
    "(\n",
    "    spy_train_data\n",
    "    .pipe(RSI)\n",
    "    .pipe(macd)\n",
    "    .pipe(generate_signals_rsi_macd)\n",
    "    .pipe(compute_strategy_return)\n",
    "    .pipe(compute_drawdown)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e41dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_test_data_rsi_macd = \\\n",
    "(\n",
    "    spy_test_data\n",
    "    .pipe(RSI)\n",
    "    .pipe(macd)\n",
    "    .pipe(generate_signals_rsi_macd)\n",
    "    .pipe(compute_strategy_return)\n",
    "    .pipe(compute_drawdown)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef150e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_test_data_rsi_macd[['cum_return','strategy_return']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e03e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_buy_new_high(\n",
    "        old_df,\n",
    "        num_long_entry:int,\n",
    "        num_short_entry: int,\n",
    "        num_long_exit:int,\n",
    "        num_short_exit: int) -> pd.DataFrame:\n",
    "    \n",
    "    df = old_df.copy()\n",
    "\n",
    "    df['delta'] =\\\n",
    "    (\n",
    "        df['Close']\n",
    "        .diff()\n",
    "    )\n",
    "\n",
    "    df['up_trend'] =\\\n",
    "    (\n",
    "        (\n",
    "            df['delta'] > 0\n",
    "        )\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "    df['down_trend'] =\\\n",
    "    (\n",
    "        (\n",
    "            df['delta'] < 0\n",
    "        )\n",
    "        .astype(int)\n",
    "    )\n",
    "    \n",
    "    #entry\n",
    "    df['entry_short'] = \\\n",
    "    (\n",
    "        df['up_trend']\n",
    "        .rolling(num_short_entry)\n",
    "        .sum() \n",
    "        == \n",
    "        num_short_entry\n",
    "    )\n",
    "\n",
    "    df['entry_long'] = \\\n",
    "    (\n",
    "        df['down_trend']\n",
    "        .rolling(num_long_entry)\n",
    "        .sum() \n",
    "        == \n",
    "        num_long_entry\n",
    "    )\n",
    "\n",
    "    df['exit_short']  = \\\n",
    "    (\n",
    "        df['down_trend']\n",
    "        .rolling(num_short_exit)\n",
    "        .sum() \n",
    "        == \n",
    "        num_short_exit\n",
    "    )\n",
    "\n",
    "    df['exit_long']  = \\\n",
    "    (\n",
    "        df['up_trend']\n",
    "        .rolling(num_long_exit)\n",
    "        .sum() \n",
    "        == \n",
    "        num_long_exit\n",
    "    )\n",
    "\n",
    "    signals = []\n",
    "    signal = 0\n",
    "\n",
    "    for short_entry, long_entry, short_exit, long_exit in zip(\n",
    "        df['entry_short'], \n",
    "        df['entry_long'],\n",
    "        df['exit_short'], \n",
    "        df['exit_long']\n",
    "    ):\n",
    "\n",
    "        if signal == 0:\n",
    "            if short_entry:\n",
    "                signal = -1\n",
    "            if long_entry:\n",
    "                signal = 1\n",
    "\n",
    "        elif signal == 1 and long_exit:\n",
    "            signal = 0\n",
    "\n",
    "        elif signal == -1 and short_exit:\n",
    "            signal = 0\n",
    "\n",
    "        signals.append(signal)\n",
    "\n",
    "    df['signal'] = signals\n",
    "\n",
    "    #stack buy\n",
    "    df['position'] = \\\n",
    "    (\n",
    "        df['signal']\n",
    "        .ffill()\n",
    "        .shift(1)\n",
    "        .fillna(0)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c232f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_train_data['Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ret = pd.DataFrame()\n",
    "\n",
    "for entry_l in range(2,10):\n",
    "    for entry_s in range(2,10):\n",
    "        for exit_l in range(2,10):\n",
    "            for exit_s in range(2,10):\n",
    "                a = spy_train_data.copy()\n",
    "                a = \\\n",
    "                (\n",
    "                    setup_buy_new_high(a,entry_l,entry_s,exit_l,exit_s)\n",
    "                    .pipe(compute_strategy_return)\n",
    "                    .pipe(compute_drawdown)\n",
    "                )\n",
    "                df_ret[f'stra_ret_entry{entry_l}_{entry_s}_exit{exit_l}_{exit_s}'] = a[['strategy_return']].copy()\n",
    "df_ret['buy_and_hold'] = a['cum_return'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbdae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_ret.iloc[-1].sort_values(ascending=False)).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14643223",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =\\\n",
    "(\n",
    "    setup_buy_new_high(\n",
    "\n",
    "        spy_test_data,\n",
    "        2,\n",
    "        2,\n",
    "        4,\n",
    "        2\n",
    "    )\n",
    "    .pipe(compute_strategy_return)\n",
    "    .pipe(compute_drawdown)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[['cum_return','strategy_return']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150bd52",
   "metadata": {},
   "source": [
    "## (1C) Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_ticker = [\"META\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\", \"SPY\"]\n",
    "forex_ticker = [\"DEXUSEU\", \"DEXJPUS\", \"DEXUSUK\", \"DEXSZUS\", \"DEXCAUS\", \"DEXUSAL\", \"DEXUSNZ\", \"DEXNOUS\", \"DEXSDUS\"]\n",
    "index_ticker = [\"DX-Y.NYB\",\"GC=F\", \"CL=F\", \"HG=F\", \"^VIX\"]\n",
    "yield_ticker = [\"^IRX\", \"^FVX\", \"^TNX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e21e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "### download data\n",
    "stock_data =\\\n",
    "(\n",
    "    download_data(stock_ticker,\n",
    "                  close_only = True)\n",
    ")\n",
    "\n",
    "forex_data =\\\n",
    "(\n",
    "    pdr\n",
    "    .get_data_fred(forex_ticker,\n",
    "                  stock_data.index[0],\n",
    "                  stock_data.index[-1])\n",
    ")\n",
    "\n",
    "index_data =\\\n",
    "(\n",
    "    download_data(index_ticker,\n",
    "                  close_only = True)\n",
    ")\n",
    "\n",
    "yield_data =\\\n",
    "(\n",
    "    download_data(yield_ticker,\n",
    "                  close_only = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd38b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data = index_data.where(index_data > 0)\n",
    "index_data = index_data.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac96792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# technical indicators\n",
    "technical_data1 = {}\n",
    "technical_data2 = {}\n",
    "target_data =\\\n",
    "(\n",
    "    stock_data.loc[: , \"SPY\"]\n",
    "    .copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sma_periods = [5, 10, 21, 50, 63, 100, 200, 252, 500]\n",
    "ema_periods = [5, 10, 21, 50, 63, 100, 200, 252, 500]\n",
    "rsi_periods = [2, 5, 7, 10, 14, 21, 28]\n",
    "ROC_periods = [5, 10, 21, 50, 63, 126, 200, 252]        \n",
    "MOM_periods = [5, 10, 21, 50, 63, 126, 200, 252]         \n",
    "stochastic_periods = [5, 10, 14, 21]\n",
    "return_period = 5    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb14bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sma\n",
    "for i in sma_periods:\n",
    "    technical_data1[f\"{i}_SMA\"] =\\\n",
    "    (\n",
    "        target_data\n",
    "        .rolling(window = i)\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    # ema\n",
    "for i in ema_periods:\n",
    "    technical_data1[f\"{i}_EMA\"] =\\\n",
    "    (\n",
    "        target_data\n",
    "        .ewm(span = i)\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "# rsi\n",
    "def RSI(data, period):\n",
    "    price_diff =\\\n",
    "    (\n",
    "        data\n",
    "        .diff()\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    up = price_diff * 0\n",
    "    down = up.copy()\n",
    "\n",
    "    up[price_diff > 0] = price_diff[price_diff > 0]\n",
    "    down[price_diff < 0] = -price_diff[price_diff < 0]\n",
    "\n",
    "    up[up.index[period - 1]] = np.mean( up[ :period])\n",
    "    up = up.drop(up.index[ :(period - 1)]\n",
    "                )\n",
    "    down[down.index[period - 1]] = np.mean( down[ :period])\n",
    "    down = down.drop(down.index[ :(period - 1)]\n",
    "                    )\n",
    "\n",
    "    rs =\\\n",
    "    (\n",
    "        up.ewm(com = period - 1,\n",
    "               adjust = False).mean()\n",
    "        /\n",
    "        down.ewm(com = period - 1,\n",
    "                 adjust = False).mean()\n",
    "    )\n",
    "\n",
    "    return 100 - 100 / (1 + rs)\n",
    "    \n",
    "for i in rsi_periods:\n",
    "    technical_data2[f\"{i}_RSI\"] = RSI(target_data, i)\n",
    "\n",
    "# RoC\n",
    "def ROC(data, period):\n",
    "    M = data.diff(period - 1)\n",
    "    N = data.shift(period - 1)\n",
    "    ROC = (M / N) * 100\n",
    "\n",
    "    return ROC\n",
    "\n",
    "for i in ROC_periods:\n",
    "    technical_data2[f\"{i}_ROC\"] = ROC(target_data, i)   \n",
    "\n",
    "# Price momentum\n",
    "def MOM(data, periods):\n",
    "    MOM = data.diff(periods)\n",
    "    return MOM\n",
    "for i in MOM_periods:\n",
    "    technical_data2[f\"{i}_MOM\"] = MOM(target_data, i)\n",
    "\n",
    "# Stochastic Oscillator data\n",
    "stochastic_oscillator_data =\\\n",
    "(\n",
    "    yf\n",
    "    .download(\"SPY\",\n",
    "              start_date,\n",
    "              end_date)\n",
    "    [[\"Close\", \"Low\", \"High\"]]\n",
    ")\n",
    "\n",
    "stochastic_oscillator_data.columns =\\\n",
    "(\n",
    "    stochastic_oscillator_data\n",
    "    .columns\n",
    "    .droplevel(1)\n",
    ")\n",
    "\n",
    "# Stochastic Oscillator\n",
    "def STOK(df = stochastic_oscillator_data\n",
    "         , period = 1):\n",
    "    STOK =\\\n",
    "    (\n",
    "        ((df[\"Close\"] - df[\"Low\"].rolling(period).min())\n",
    "        /\n",
    "        (df[\"High\"].rolling(period).max() - df[\"Low\"].rolling(period).min())\n",
    "        ) * 100\n",
    "    )\n",
    "\n",
    "    return STOK\n",
    "\n",
    "def STOD(df = stochastic_oscillator_data\n",
    "         , period = 1):\n",
    "    STOK =\\\n",
    "    (\n",
    "        ((df[\"Close\"] - df[\"Low\"].rolling(period).min())\n",
    "        /\n",
    "        (df[\"High\"].rolling(period).max() - df[\"Low\"].rolling(period).min())\n",
    "        ) * 100\n",
    "    )\n",
    "\n",
    "    STOD = STOK.rolling(3).mean()\n",
    "    return STOD\n",
    "\n",
    "for i in stochastic_periods:\n",
    "        technical_data2[f\"{i}_%K\"] = STOK(period = i)\n",
    "        technical_data2[f\"{i}_%D\"] = STOD(period = i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f0a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to df    \n",
    "technical_data1 =\\\n",
    "(\n",
    "    pd\n",
    "    .DataFrame(technical_data1)\n",
    ")\n",
    "\n",
    "technical_data2 =\\\n",
    "(\n",
    "    pd\n",
    "    .DataFrame(technical_data2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c19403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting of variables\n",
    "Y =\\\n",
    "(\n",
    "    np\n",
    "    .log(stock_data.loc[ : , \"SPY\"]\n",
    "        )\n",
    "    .diff(return_period)\n",
    "    .shift(-return_period)\n",
    ")\n",
    "\n",
    "Y.name =\\\n",
    "(\n",
    "    Y\n",
    "    .name\n",
    "    +\n",
    "    \"_pred\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f92622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 =\\\n",
    "(\n",
    "    np\n",
    "    .log(stock_data.loc[ : , (\"META\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\")]\n",
    "        )\n",
    "    .diff(return_period)   \n",
    ")\n",
    "\n",
    "X2 =\\\n",
    "(\n",
    "    np\n",
    "    .log(forex_data)\n",
    "    .diff(return_period)\n",
    ")\n",
    "\n",
    "X3 =\\\n",
    "(\n",
    "    np\n",
    "    .log(index_data)\n",
    "    .diff(return_period)\n",
    ")\n",
    "\n",
    "X4 =\\\n",
    "(\n",
    "    yield_data\n",
    "    .diff(return_period)\n",
    "    * 100\n",
    ")\n",
    "\n",
    "X5 =\\\n",
    "pd.concat(\n",
    "    [np\n",
    "     .log(stock_data.loc[ : , \"SPY\"]\n",
    "         )\n",
    "     .diff(i) for i in [return_period,\n",
    "                        return_period * 3, # 15\n",
    "                        return_period * 6, # 30\n",
    "                        return_period * 12 # 60\n",
    "                       ]\n",
    "    ],\n",
    "    axis = 1\n",
    ").dropna()\n",
    "X5.columns = [\"SPY_DT\", \"SPY_3DT\", \"SPY_6DT\", \"SPY_12DT\"]\n",
    "\n",
    "\n",
    "X6 =\\\n",
    "(\n",
    "    np\n",
    "    .log(technical_data1)\n",
    "    .diff(return_period)\n",
    ")\n",
    "\n",
    "X7 =\\\n",
    "(\n",
    "    technical_data2\n",
    "    .diff(return_period)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d402cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =\\\n",
    "(\n",
    "    pd\n",
    "    .concat([X1, X2, X3, X4, X5, X6],\n",
    "           axis =1)\n",
    ")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b3f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =\\\n",
    "(\n",
    "    pd\n",
    "    .concat([Y, X],\n",
    "           axis = 1)\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "data =\\\n",
    "(\n",
    "    data\n",
    "    .iloc[ : :return_period, : ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08724ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y =\\\n",
    "(\n",
    "    data\n",
    "    .loc[ : ,Y.name]\n",
    ")\n",
    "\n",
    "X =\\\n",
    "(\n",
    "    data\n",
    "    .loc[ : , X.columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = 0.25\n",
    "\n",
    "train_size = int(len(X) * (1 - testing_set))\n",
    "\n",
    "Y_train, Y_test =\\\n",
    "(\n",
    "    Y[0 : train_size],\n",
    "    Y[train_size:len(Y)]\n",
    ")\n",
    "\n",
    "X_train, X_test =\\\n",
    "(\n",
    "    X[0: train_size],\n",
    "    X[train_size:len(X)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87726e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a3044",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled =\\\n",
    "    (\n",
    "        pd\n",
    "        .DataFrame(\n",
    "            scaler.transform(X_train),\n",
    "            index = X_train.index,\n",
    "            columns = X_train.columns\n",
    "        )\n",
    "    )\n",
    "\n",
    "X_test_scaled =\\\n",
    "    (\n",
    "        pd\n",
    "        .DataFrame(\n",
    "            scaler.transform(X_test),\n",
    "            index = X_test.index,\n",
    "            columns = X_test.columns\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953fdaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "models =\\\n",
    "[\n",
    "    (\"LR\", LinearRegression()),\n",
    "    (\"Elastic Net Penalty\", ElasticNet()),\n",
    "    (\"LASSO\", Lasso()),\n",
    "    (\"Support Vector Machine\", SVR()),\n",
    "    (\"K-Nearest Neighbors\", KNeighborsRegressor()),\n",
    "    (\"Decision Tree\", DecisionTreeRegressor()),\n",
    "    (\"Extra Trees Algo\", ExtraTreesRegressor()),\n",
    "    (\"Random Forest\", RandomForestRegressor()),\n",
    "    (\"Gradient Boosting\", GradientBoostingRegressor()),\n",
    "    (\"Adaptive Boosting\", AdaBoostRegressor())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "kfold_results = []\n",
    "\n",
    "best_models = {}\n",
    "ml_equity_curves = {}\n",
    "results = []\n",
    "ncomps_list = [5, 10 ,15, 20, 25, 30, 35, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd22bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 627\n",
    "num_folds = 10\n",
    "ncomps = 30\n",
    "metric = \"neg_mean_squared_error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dc659",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_for_plot = TruncatedSVD(n_components=ncomps, random_state=seed)\n",
    "svd_for_plot.fit(X_train_scaled)\n",
    "\n",
    "plt_data = pd.DataFrame(\n",
    "    svd_for_plot.explained_variance_ratio_.cumsum() * 100,\n",
    "    index=np.arange(1, ncomps + 1),\n",
    "    columns=[\"cum_var_explained\"]\n",
    ")\n",
    "\n",
    "ax = plt_data.plot(kind=\"line\", figsize=(20, 10), style=\"o-\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_xlabel(\"PCs\")\n",
    "ax.set_ylabel(\"Percentage Explained\")\n",
    "ax.legend(\"\")\n",
    "\n",
    "print(\n",
    "    \"Variance preserved by first {} components == {:.2%}\".format(\n",
    "        ncomps,\n",
    "        svd_for_plot.explained_variance_ratio_.cumsum()[-1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids =\\\n",
    "{\n",
    "    \"LR\":\\\n",
    "    {\n",
    "        \"model__fit_intercept\": [True, False]\n",
    "    },\n",
    "\n",
    "    \"Elastic Net Penalty\":\\\n",
    "    {\n",
    "        \"model__alpha\": np.logspace(-4, 2, 7),\n",
    "        \"model__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "        \"model__max_iter\": [5000]\n",
    "    },\n",
    "\n",
    "    \"LASSO\":\\\n",
    "    {\n",
    "        \"model__alpha\": np.logspace(-5, 1, 7),\n",
    "        \"model__max_iter\": [5000]\n",
    "    },\n",
    "\n",
    "    \"Support Vector Machine\":\\\n",
    "    {\n",
    "        \"model__C\": [0.1, 1, 10],\n",
    "        \"model__gamma\": [\"scale\", \"auto\"],\n",
    "        \"model__epsilon\": [0.001, 0.01, 0.1],\n",
    "        \"model__kernel\": [\"rbf\"]\n",
    "    },\n",
    "\n",
    "    \"K-Nearest Neighbors\":\\\n",
    "    {\n",
    "        \"model__n_neighbors\": [3, 5, 9, 15],\n",
    "        \"model__weights\": [\"uniform\", \"distance\"]\n",
    "    },\n",
    "\n",
    "    \"Decision Tree\":\\\n",
    "    {\n",
    "        \"model__max_depth\": [3, 5, 10, None],\n",
    "        \"model__min_samples_split\": [2, 5, 10],\n",
    "        \"model__min_samples_leaf\": [1, 2, 4]\n",
    "    },\n",
    "\n",
    "    \"Extra Trees Algo\":\\\n",
    "    {\n",
    "        \"model__n_estimators\": [100, 300],\n",
    "        \"model__max_depth\": [None, 10],\n",
    "        \"model__min_samples_split\": [2, 5, 10],\n",
    "        \"model__min_samples_leaf\": [1, 2, 4],\n",
    "        \"model__max_features\": [\"sqrt\", None]\n",
    "    },\n",
    "\n",
    "    \"Random Forest\":\\\n",
    "    {\n",
    "        \"model__n_estimators\": [150, 300],\n",
    "        \"model__max_depth\": [None, 10],\n",
    "        \"model__min_samples_split\": [2, 10],\n",
    "        \"model__min_samples_leaf\": [1, 2],\n",
    "        \"model__max_features\": [\"sqrt\", None]\n",
    "    },\n",
    "\n",
    "    \"Gradient Boosting\":\\\n",
    "    {\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__learning_rate\": [0.05, 0.1],\n",
    "        \"model__max_depth\": [2, 3],\n",
    "        \"model__subsample\": [0.6, 0.8],\n",
    "        \"model__min_samples_split\": [2],\n",
    "        \"model__min_samples_leaf\": [1, 2]\n",
    "    },\n",
    "\n",
    "    \"Adaptive Boosting\":\\\n",
    "    {\n",
    "        \"model__n_estimators\": [50, 150],\n",
    "        \"model__learning_rate\": [0.05, 0.5],\n",
    "        \"model__loss\": [\"linear\", \"square\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acffbada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ml_results(y_true,\n",
    "                        y_pred,\n",
    "                        return_period = return_period,\n",
    "                        initial_capital = 1e5\n",
    "                        ):\n",
    "    data =\\\n",
    "    (\n",
    "        pd\n",
    "        .concat(\n",
    "            [y_true.rename(\"y_true\"),\n",
    "             y_pred.rename(\"y_pred\")],\n",
    "             axis = 1\n",
    "        )\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    signal =\\\n",
    "    (\n",
    "        np\n",
    "        .sign(data[\"y_pred\"])   \n",
    "    )\n",
    "\n",
    "    position =\\\n",
    "    (\n",
    "        signal\n",
    "        .shift(1)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    strategy_returns =\\\n",
    "    (\n",
    "        position\n",
    "        *\n",
    "        data[\"y_true\"]\n",
    "    )\n",
    "\n",
    "    equity_curve =\\\n",
    "    (\n",
    "        np\n",
    "        .exp(strategy_returns.cumsum())\n",
    "        *\n",
    "        initial_capital\n",
    "    )\n",
    "\n",
    "    periods_per_year =\\\n",
    "    (\n",
    "        252\n",
    "        /\n",
    "        return_period\n",
    "    )\n",
    "\n",
    "    mean_return =\\\n",
    "    (\n",
    "        strategy_returns\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    std_return =\\\n",
    "    (\n",
    "        strategy_returns\n",
    "        .std()\n",
    "    )\n",
    "\n",
    "    sharpe =\\\n",
    "    (\n",
    "        mean_return\n",
    "        /\n",
    "        std_return\n",
    "        *\n",
    "        np.sqrt(periods_per_year)\n",
    "    )\n",
    "\n",
    "    n_periods = strategy_returns.shape[0]\n",
    "    years = n_periods / periods_per_year\n",
    "\n",
    "    final_equity = equity_curve.iloc[-1]\n",
    "\n",
    "    cagr =\\\n",
    "    (\n",
    "        (final_equity / initial_capital) ** (1/ years)\n",
    "        - 1\n",
    "    )\n",
    "\n",
    "    running_max =\\\n",
    "    (\n",
    "        equity_curve\n",
    "        .cummax()\n",
    "    )\n",
    "\n",
    "    drawdown =\\\n",
    "    (\n",
    "        equity_curve\n",
    "        /\n",
    "        running_max\n",
    "        - 1\n",
    "    )\n",
    "\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    results =\\\n",
    "    {\n",
    "        \"sharpe\": sharpe,\n",
    "        \"cagr\": cagr,\n",
    "        \"max_drawdown\": max_drawdown,\n",
    "        \"final_equity\": final_equity,\n",
    "        \"equity_curve\": equity_curve\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ncomps in ncomps_list:\n",
    "    print(f\"\\n===== Running models for ncomps = {ncomps} =====\")\n",
    "\n",
    "    for name, model in models:\n",
    "\n",
    "        names.append(f\"{name}_nc{ncomps}\")\n",
    "\n",
    "        kfold =\\\n",
    "        (\n",
    "            KFold(n_splits = num_folds,\n",
    "                random_state = seed,\n",
    "                shuffle = True)\n",
    "        )\n",
    "\n",
    "        # run SVD\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svd\", TruncatedSVD(n_components = ncomps, random_state = seed)),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "\n",
    "        param_grid = param_grids.get(name, {})\n",
    "\n",
    "        grid_search =\\\n",
    "        (\n",
    "            GridSearchCV(estimator = pipe,\n",
    "                        param_grid = param_grid,\n",
    "                        cv = kfold,\n",
    "                        scoring = metric,\n",
    "                        n_jobs = -1)\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, Y_train)\n",
    "\n",
    "        res = grid_search.best_estimator_\n",
    "        best_models[(name, ncomps)] = res\n",
    "        best_index = grid_search.best_index_\n",
    "\n",
    "        cv_scores =\\\n",
    "        (\n",
    "            np\n",
    "            .array(\n",
    "                [grid_search.cv_results_[f\"split{i}_test_score\"][best_index]\n",
    "                for i in range(num_folds)]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        cv_scores = -1 * cv_scores\n",
    "\n",
    "        kfold_results.append(cv_scores)\n",
    "\n",
    "        train_result = mean_squared_error(res.predict(X_train), Y_train)\n",
    "        train_results.append(train_result)\n",
    "\n",
    "        # Assess the performance in Testing Set\n",
    "\n",
    "        test_result = mean_squared_error(res.predict(X_test), Y_test)\n",
    "        test_results.append(test_result)\n",
    "\n",
    "        y_pred_test =\\\n",
    "        (\n",
    "            pd\n",
    "            .Series(res.predict(X_test),\n",
    "                    index = Y_test.index,\n",
    "                    name = f\"{name}_nc{ncomps}_pred\"\n",
    "                    )\n",
    "        )\n",
    "\n",
    "        bt_results =\\\n",
    "        (\n",
    "            calculate_ml_results(y_true = Y_test,\n",
    "                                y_pred = y_pred_test)\n",
    "        )\n",
    "        \n",
    "        ml_equity_curves[(name, ncomps)] = bt_results[\"equity_curve\"]\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"Model\": name,\n",
    "                \"ncomps\": ncomps,\n",
    "                \"CV_MSE_mean\": cv_scores.mean(),\n",
    "                \"CV_MSE_std\":  cv_scores.std(),\n",
    "                \"Train_MSE\":   train_result,\n",
    "                \"Test_MSE\":    test_result,\n",
    "                \"Sharpe\":      bt_results[\"sharpe\"],\n",
    "                \"CAGR\":        bt_results[\"cagr\"],\n",
    "                \"Max_Drawdown\":bt_results[\"max_drawdown\"],\n",
    "                \"Final_Equity\":bt_results[\"final_equity\"],\n",
    "                \"Best_Params\": grid_search.best_params_\n",
    "            }\n",
    "        )\n",
    "        user_interface_message = \"%s: %f (%f) %f %f Sharpe=%f CAGR=%f MDD=%f Final=%f\" %\\\n",
    "        (\n",
    "            name, \n",
    "            cv_scores.mean(), \n",
    "            cv_scores.std(), \n",
    "            train_result, \n",
    "            test_result,\n",
    "            bt_results[\"sharpe\"],\n",
    "            bt_results[\"cagr\"],\n",
    "            bt_results[\"max_drawdown\"],\n",
    "            bt_results[\"final_equity\"]\n",
    "        )\n",
    "        print(user_interface_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df =\\\n",
    "(\n",
    "    pd\n",
    "    .DataFrame(results)\n",
    "    .set_index([\"Model\", \"ncomps\"])\n",
    ").sort_values(by = \"Final_Equity\",\n",
    "              ascending = False)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdccdea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lets_plot import *\n",
    "LetsPlot.setup_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1404361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_plot =\\\n",
    "(\n",
    "    pd\n",
    "    .DataFrame(\n",
    "        {\"Algorithms\": names * 2,\n",
    "         \"Data\": [\"Training Set\"] * len(names) + [\"Testing Set\"] * len(names),\n",
    "         \"Performance\": train_results + test_results\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, ncomps),  fitted_pipe in best_models.items():\n",
    "    print(f\"\\n=== Fitting and plotting for model: {name} ===\")\n",
    "\n",
    "    # predict on test set\n",
    "    y_predictions = fitted_pipe.predict(X_test)\n",
    "\n",
    "    # Convert predictions to Series aligned with Y_test index\n",
    "    y_predictions = pd.Series(\n",
    "        data=y_predictions,\n",
    "        index=Y_test.index,\n",
    "        name=f\"{name} Predictions\"\n",
    "    )\n",
    "\n",
    "    # Build cumulative return curves\n",
    "    actual_results = np.exp(Y_test).cumprod()\n",
    "    pred_results   = np.exp(y_predictions).cumprod()\n",
    "\n",
    "    difference = actual_results - pred_results\n",
    "\n",
    "    # Build DataFrame for plotting\n",
    "    df_outcome = pd.DataFrame(\n",
    "        {\n",
    "            \"date\": actual_results.index,\n",
    "            \"future SPY\": actual_results.values,\n",
    "            \"predicted SPY\": pred_results.values,\n",
    "            \"difference\": difference.values\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Long format for lets-plot\n",
    "    df_outcome_ggplot = df_outcome.melt(\n",
    "        id_vars=[\"date\", \"difference\"],\n",
    "        var_name=\"series\",\n",
    "        value_name=\"value\"\n",
    "    )\n",
    "\n",
    "    # Dynamic y-limit so plots scale nicely\n",
    "    y_max = float(df_outcome_ggplot[\"value\"].max() * 1.1)\n",
    "\n",
    "    # Plot using lets-plot\n",
    "    p = \\\n",
    "    (\n",
    "        ggplot(df_outcome_ggplot, aes(x=\"date\", y=\"value\", color=\"series\"))\n",
    "        + geom_line()\n",
    "        + geom_point()\n",
    "        + scale_y_continuous(limits=[0, y_max])\n",
    "        + scale_color_manual(\n",
    "            values={\n",
    "                \"future SPY\": \"blue\",\n",
    "                \"predicted SPY\": \"red\"\n",
    "            }\n",
    "        )\n",
    "        + ggtitle(f\"Predicting SPY Cumulative Returns with {name}\")\n",
    "        + xlab(\"Date\")\n",
    "        + ylab(\"Cumulative Returns\")\n",
    "        + theme(legend_position=\"top\")\n",
    "        + ggsize(1000, 500)\n",
    "    )\n",
    "\n",
    "    # show plot for this model\n",
    "    p.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_pred = pd.Series(\n",
    "    data = 1.0,\n",
    "    index = Y_test.index,\n",
    "    name = \"buy_and_hold_pred\"\n",
    ")\n",
    "\n",
    "bh_results = calculate_ml_results(\n",
    "    y_true = Y_test,\n",
    "    y_pred = bh_pred,        \n",
    "    return_period = return_period,\n",
    "    initial_capital = 1e5    \n",
    ")\n",
    "\n",
    "bh_sharpe = bh_results[\"sharpe\"]\n",
    "bh_cagr = bh_results[\"cagr\"]\n",
    "bh_mdd = bh_results[\"max_drawdown\"]\n",
    "bh_final_equity = bh_results[\"final_equity\"]\n",
    "bh_equity_curve = bh_results[\"equity_curve\"]\n",
    "\n",
    "print(\"Buy & Hold SPY (test period)\")\n",
    "print(f\"Sharpe:{bh_sharpe:.3f}\")\n",
    "print(f\"CAGR:{bh_cagr:.3%}\")\n",
    "print(f\"Max Drawdown:{bh_mdd:.2%}\")\n",
    "print(f\"Final Balance:{bh_final_equity:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_name = \"Gradient Boosting\"\n",
    "strategy_ncomps = 10\n",
    "\n",
    "strategy_equity = ml_equity_curves[(strategy_name, strategy_ncomps)]\n",
    "bh_equity = bh_equity_curve   \n",
    "\n",
    "df_plot = pd.DataFrame({\n",
    "    \"date\": strategy_equity.index,\n",
    "    \"Strategy\": strategy_equity.values,\n",
    "    \"Buy_and_Hold\": bh_equity.reindex(strategy_equity.index).values\n",
    "})\n",
    "\n",
    "df_long = df_plot.melt(\n",
    "    id_vars=\"date\",\n",
    "    var_name=\"series\",\n",
    "    value_name=\"equity\"\n",
    ")\n",
    "\n",
    "p =\\\n",
    "(\n",
    "    ggplot(df_long, aes(x=\"date\", y=\"equity\", color=\"series\"))\n",
    "    + geom_line()\n",
    "    + ggtitle(f\"Equity Curve: {strategy_name} (ncomps={strategy_ncomps}) vs Buy & Hold SPY\")\n",
    "    + xlab(\"Date\")\n",
    "    + ylab(\"Portfolio Value\")\n",
    "    + theme(legend_position=\"top\")\n",
    "    + ggsize(1000, 500)\n",
    ")\n",
    "\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a1a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy data\n",
    "row = results_df.loc[(strategy_name, strategy_ncomps)]\n",
    "st_sharpe = row[\"Sharpe\"]\n",
    "st_cagr = row[\"CAGR\"]\n",
    "st_mdd = row[\"Max_Drawdown\"]\n",
    "st_final_equity = row[\"Final_Equity\"]\n",
    "\n",
    "# Compute differences (strategy minus buy & hold)\n",
    "sharpe_diff = st_sharpe - bh_sharpe\n",
    "cagr_diff_pct = (st_cagr - bh_cagr) * 100 \n",
    "mdd_diff_pct = (st_mdd - bh_mdd)  * 100\n",
    "final_equity_diff = st_final_equity - bh_final_equity\n",
    "\n",
    "print(f\"=== Strategy vs Buy & Hold (Test Period) ===\")\n",
    "print(f\"Sharpe (Strategy):{st_sharpe:.3f}\")\n",
    "print(f\"Sharpe (Buy & Hold):{bh_sharpe:.3f}\")\n",
    "print(f\"Sharpe Difference:{sharpe_diff:+.3f}\")\n",
    "\n",
    "print()\n",
    "print(f\"CAGR (Strategy):{st_cagr*100:6.2f}%.\")\n",
    "print(f\"CAGR (Buy & Hold):{bh_cagr*100:6.2f}%.\")\n",
    "print(f\"CAGR Difference:{cagr_diff_pct:+6.2f}%.\")\n",
    "\n",
    "print()\n",
    "print(f\"Max Drawdown (Strategy):{st_mdd*100:6.2f}%\")\n",
    "print(f\"Max Drawdown (B&H):{bh_mdd*100:6.2f}%\")\n",
    "print(f\"MDD Difference:{mdd_diff_pct:+6.2f}% \")\n",
    "\n",
    "print()\n",
    "print(f\"Final Equity (Strategy):{st_final_equity:,.2f}\")\n",
    "print(f\"Final Equity (B&H):{bh_final_equity:,.2f}\")\n",
    "print(f\"Final Equity Difference:+${final_equity_diff:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da8363",
   "metadata": {},
   "source": [
    "# Part 2: Visualisations and Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d40dc",
   "metadata": {},
   "source": [
    "**The 3 Strategies**\n",
    "\n",
    "1. Momentum Trading Strategy: Moving Average\n",
    "\n",
    "2. Mean-Reverting Strategy:\n",
    "\n",
    "3. Gradient Boosting Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b54b924",
   "metadata": {},
   "source": [
    "# Part 3. Executive Summary of Trading Strategies and Backtesting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a35d32",
   "metadata": {},
   "source": [
    "## The 3 Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6351c",
   "metadata": {},
   "source": [
    "**The 3 Strategies employed** includes one from each category, with the results compared against the benchmark return from the periods of `11 February 2021` to `12 November 2025`\n",
    "\n",
    "_Strategy A: (Momentum Trading)_ \n",
    "\n",
    "\n",
    "_Strategy B: (Mean-Reversion)_\n",
    "\n",
    "\n",
    "_Strategy C: (Machine Learning) - Gradient Boosting_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbfd5c2",
   "metadata": {},
   "source": [
    "<font size = 4.5>_**Metrics Generated**_</font>\n",
    "\n",
    "**1. Sharpe Ratio** <br />\n",
    "Measures risk-adjusted return by scaling the average return by its volatility. A higher Sharpe Ratio indicates that a strategy generates more return per unit of risk.\n",
    "\n",
    "**2. Compound Annual Growth Rate (CAGR)** <br />\n",
    "Summarises the long-run growth rate of the portfolio. It captures how quickly wealth compounds over the full sample period.\n",
    "\n",
    "**3. Maximum and Longest Drawdown (MDD)** <br />\n",
    "Quantifies the worst peak-to-trough loss experienced by the strategy. This is a key indicator of downside risk and how long the portfolio experiences drawdown, which is not a rational investor with a degree of risk aversion would like to see.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf2805",
   "metadata": {},
   "source": [
    "## Strategy A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4890bac0",
   "metadata": {},
   "source": [
    "Strategy A is built on the idea that returns tend to exhibit persistence: strong recent performance can be followed by further gains, while recent weakness can be followed by additional losses. In practice, we construct a momentum signal using past S&P 500 returns over a fixed lookback window. When the recent cumulative return is sufficiently positive, the strategy takes or increases a long position; when the recent cumulative return is sufficiently negative, the strategy either reduces risk or, depending on the rule specification, may take a short position.\n",
    "\n",
    "The economic intuition is that momentum benefits from extended trending regimes: prolonged bull markets or deep bear markets in which price moves in one direction for some time. Conversely, the strategy is vulnerable to sideways markets with frequent reversals, where trend signals whipsaw and turnover increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95647a8",
   "metadata": {},
   "source": [
    "**Summary of Results**\n",
    "\n",
    "Portfolio       |   Strategy A      |   Benchmark   |\n",
    "--              |   --              |      --       |\n",
    "Sharpe          |   1.58            |   1.09        |\n",
    "CAGR            |   28.55%          |  19.25%       |\n",
    "Max Drawdown    | -13.02%           |   -18.25%     |\n",
    "Final Value     |   $223,071.91     | $175,483.65   |\n",
    "\n",
    "It can be seen that strategy A is almost an exact similar returns. This is because the momentum strategy reflected the economic environment where the SPY continued an upward momentum.\n",
    "\n",
    "The results show that the strategy effective followed the benchmark return and maintained exposure throughout the test period, converging to a buy-and-hold strategy. Additionally, the use of weekly data up to a short MA of <mark>40 weeks (~1 year)</mark> meant that the moving average would move more meaningfully in the longer term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97647705",
   "metadata": {},
   "source": [
    "## Strategy B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5166526",
   "metadata": {},
   "source": [
    "Strategy B takes a contrarian view - instead of betting on trends, it assumes that prices tend to revert towards some fair value or medium-term equilibrium. This is operationalised by comparing the current S&P 500 level to a smoothed reference as a normalisation factor. In this case, the use of <mark>indicators insert here </mark>\n",
    "\n",
    "A typical implementation uses a standardised price change relative to its rolling mean. When the index trades far below its standardised value (a negative z-score), the strategy interprets this as an oversold condition and increases long exposure. When the index trades far above its standardised value (a positive z-score), the strategy treats this as an overbought condition and reduces or even reverses the position.\n",
    "\n",
    "The intuition is that mean-reversion strategies tend to perform better in choppy or range-bound markets, where deviations from the average are repeatedly corrected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3917c",
   "metadata": {},
   "source": [
    "**Summary of Results**\n",
    "\n",
    "Portfolio       |   Strategy B      |   Benchmark   |\n",
    "--              |   --              |      --       |\n",
    "Sharpe          |   1.58            |   1.09        |\n",
    "CAGR            |   28.55%          |  19.25%       |\n",
    "Max Drawdown    | -13.02%           |   -18.25%     |\n",
    "Final Value     |   $223,071.91     | $175,483.65   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b67cd6",
   "metadata": {},
   "source": [
    "## Strategy C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b133bdd",
   "metadata": {},
   "source": [
    "Strategy C employs a supervised machine learning approach to predict the 5-day forward log returns of the SPY ETF. A panel of models was run using a pipeline of StandScaler and Truncated SVD with the respective hyper-parameter tuning for each model as well as a 10-fold cross-validation. The metric used for training the model was negative mean-squared error. The goal was to get the closest error to 0. The best tuned training models were then tested on a list of Truncated SVD values to see which number of components yielded the best results out-of-sample. The final results were sorted and the model with the best final equity was chosen.\n",
    "\n",
    "The feature set comprised of:\n",
    "- MAANG stocks (META, AMZN, AAPL, NFLX, GOOG) as they are large consitutents of the SPY and their moves can drive the overall direction of the index.\n",
    "- G10 foreign exchange currencies (9 currency pairs) the movement of the currencies can show potential information about potential stock purchase flow as foreigners would have to sell their local currency and buy USD to buy US stocks.\n",
    "- Commodities and volatility index (DXY, Gold, Crude Oil, Copper, VIX) as broad macro and risk-sentiment indicators to show dollar demand and risk off or risk-off attitudes. broad USD dynamics (DXY), inflation / safe-haven demand (Gold, Oil), global growth / China cycle (Copper, Oil), and overall risk-on / risk-off regimes (VIX).\n",
    "- Treasury yields (3-month, 5-year, 10-year) to model the shape of the US risk-free curve and market's macro views on interest rate directions which has impact on the US economy and stock market. Also a proxy for monetary policy and the health of the economy. Steepening/flattening, which encodes recession risk vs expansion.\n",
    "- Multiple lagged SPY returns (5, 15, 30, 60 days) as historical price is supposed to capture most data or information about itself. It reflects the state of the index across different tenors and market states.\n",
    "- Technical indicators (SMA, EMA, ROC, MOM, RSI, STOK) which gives a compact and diverse summary of trend (SMA,EMA), speed and persistence of moves aka short-to-medium term momentum (ROC, MOM) and mean-reversion pressures seen in local stretch or overbought-oversold conditions (RSI, STOK).\n",
    "\n",
    "The best model from the backtest led to the use of Gradient Boosting Regression with 10 components for Truncated SVD being employed as Strategy C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b87e0",
   "metadata": {},
   "source": [
    "**Summary of Results**:\n",
    "\n",
    "Portfolio       |   Strategy C      |   Benchmark   |\n",
    "--              |   --              |      --       |\n",
    "Sharpe          |   1.58            |   1.09        |\n",
    "CAGR            |   28.55%          |  19.25%       |\n",
    "Max Drawdown    | -13.02%           |   -18.25%     |\n",
    "Final Value     |   $223,071.91     | $175,483.65   |\n",
    "\n",
    "\n",
    "Over the test period, Strategy C meaningfully outperforms a buy-and-hold SPY benchmark on both risk-adjusted and absolute returns, while also reducing drawdowns.\n",
    "\n",
    "On a risk-adjusted basis, Strategy C delivers a Sharpe ratio of 1.58, compared with 1.09 for buy-and-hold. This improvement of about +0.49 in the Sharpe ratio shows that Strategy C generates noticeably more return per unit of risk than simply holding SPY.\n",
    "\n",
    "In terms of growth, Strategy C achieves a CAGR of 28.55%, versus 19.25% for buy-and-hold, an outperformance of +9.30% per year over the test window. This translates into final equity of $223,071.91 for Strategy C versus $175,483.65 for buy-and-hold, i.e. roughly $47,588 more, or about 27% higher terminal wealth from the same starting capital.\n",
    "\n",
    "From a risk / drawdown perspective, Strategy C also improves the path of returns. Its maximum drawdown is 13.02%, compared with 18.25% for buy-and-hold, a reduction of about 5.2% in peak-to-trough loss. This indicates that Strategy C not only delivers higher returns, but does so with a smoother equity curve and better downside protection than the benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64355e5d",
   "metadata": {},
   "source": [
    "# Part 4: Self-Critique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064204c8",
   "metadata": {},
   "source": [
    "**Discussion Point 1: Engaging A 'Purist' Mindset**\n",
    "\n",
    "> In this project, we initially attempted a first a purist approach to our strategies, focusing on standalone strategies for mean-reversion, momentum trading and machine learning approaches. In a more complex world that has embraced large sets of data and permitted higher frequency of trading, this means that such strategies would not be as profitable as expected.\n",
    ">\n",
    "> Additionally, it is highly likely that institutional traders were already on the lookout for such indicators and would crowd out the strategies. An algorithm that is able to blend strategies dynamically could have a better chance at beeting the market"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce365787",
   "metadata": {},
   "source": [
    "**Discussion Point 2: Robustness versus Overfitting**\n",
    ">There was an inherent trade off between maintaining a \"robust\" model vs \"Optimisation\" of the parameters. In the backtest for strategy A and B, the performances admittedly were tested for the training period leading to models that did well but did not make good trading sense. An example was Moving Average Crossover of periods 50 and 70, where the strategy did beat the market but did not correspond to a numerically significant period.\n",
    ">\n",
    ">Another example was the use of Tech stocks as part of the supervised learning model, which was sufficiently representative of the training period of 10 years in a period of tech dominance but might not be necessarily representative for all periods. This means that in the event that the index becomes dominated by constituents other than the tech stocks, the machine learning model might be relevant in 'beating the SPY'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a347a19",
   "metadata": {},
   "source": [
    "**Discussion Point 3: Frequency of Trading vs Expected Returns**\n",
    "> Throughout the assignment, the group had recognised that the strategies had a better chance of beating the market over a longer time-period, hence the employment of weekly data over daily data. This brought up a discussion point on trading frequency and the group's expectation of outperformance of the market.\n",
    ">\n",
    "> On one hand, trading more frequently helped the models to differ much more substantially to the market, since it involved taking on and off-loading risk against the benchmark returns. However this required the signals to be a reliable predictor so that it has a higher chance to beat the market. Additionally, the costs of slippage is not accounted for when more trading signals are employed, which makes the models less robust.\n",
    ">\n",
    ">On the other hand, trading less frequently ensured that the strategy would be close to the market returns, but reduced significantly the possibility of actually beating the market. Missing certain periods in the markets could also incur large opportunity costs especially if periods of high returns were missed.\n",
    ">\n",
    "> The strategies employed hence initially assumed that more signals were better, but has since moved to employing fewer signals (strategy A and C) through employing lower frequency data. This means that in the event of high volatility in the market, these models might be more prone to underperformance since the models mostly sought to follow the market and exit/reverse position when the SPY had a sustained downturn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b648d7",
   "metadata": {},
   "source": [
    "**Discussion Point 4: Possible Lookahead Bias**\n",
    "> For supervised learning models employed, there was a possibility of lookahead bias arising from the use of treasury yield data. This is because treasury yield data are reported ex-ante on some occasions, which is not captured in the backtested data. In future model developments, the models should allow for lagged data to be incorporated into the model and further tested for performance changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a40084",
   "metadata": {},
   "source": [
    "**Discussion 5: Inconsistencies in Our Backtesting Logic**\n",
    "\n",
    ">A further limitation comes from the way our backtesting logic was implemented across the three strategies. Although the intention was to create a fair and comparable evaluation, several inconsistencies in the code may have affected the reliability of the results.\n",
    ">\n",
    ">One example is the mismatch between signal-generation timing and execution timing. In all three strategies, we implicitly allowed ourselves to see the full days closing price and immediately act on it at the same close. This was not explicitly corrected with a shift (e.g., using `.shift(1)` for the signals), which introduces a mild lookahead bias. While this may seem small, it systematically inflates strategy performance by making signals appear more responsive than they should be.\n",
    ">\n",
    ">Another issue is the inconsistent treatment of NaN values introduced by rolling windows. In Strategy A and B, early-window NaNs were simply dropped or backfilled without a clear rule, while in Strategy C the dataframe was trimmed differently due to feature alignment. These differences mean that the three strategies were effectively trained and tested on slightly different subsets of the data, which weakens the comparability of the reported performance numbers.\n",
    ">\n",
    ">Finally, our backtesting framework performed annualised return and volatility calculations using a fixed number of periods per year. Because Strategy A and B used weekly signals while Strategy C used daily features, the same formulas did not always correspond cleanly to the resampled frequency. As a result, the reported Sharpe ratios and CAGRs are not perfectly aligned across the three strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2947cfa4",
   "metadata": {},
   "source": [
    "**Discussion 6: Simplifying Assumptions in Position Sizing and Execution Logic**\n",
    "\n",
    "> A further limitation concerns how positions were sized and executed across all strategies. The group adopted a very simplified approach: when a signal is positive, allocate fully into SPY; when negative, allocate to zero. While this is consistent with the requirement to use only SPY as the tradable asset, the binary allocation rule overlooks important considerations.\n",
    ">\n",
    "> For one, this approach implicitly assumes frictionless execution. In practice, even with a single asset, execution delays or partial fills would affect realised performance. Our backtest assumes perfect execution at the computed price, which is an idealisation that likely overstates strategy returns.\n",
    ">\n",
    ">Second, the lack of position scaling meant that our strategies could not express varying levels of conviction. Signals that were only marginally positive or negative led to the same allocation as strongly trending or strongly reverting conditions. More nuanced sizing rules could have reflected signal strength and improved realism, even within the constraints of the project.\n",
    ">\n",
    ">Lastly, the execution timing used in our code did not distinguish clearly between signal generation at close and execution at next open. This introduces a mild timing bias that makes our strategies appear more reactive than they realistically could be.\n",
    ">\n",
    ">These simplifications were practical for completing the assignment efficiently, but they also highlight areas where the implementation could be improved with more careful attention to detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
